#!/usr/bin/env python3
"""
Comprehensive test for Hindi and Kannada document processing in PolyDoc
"""
import sys
import logging
import asyncio
from pathlib import Path
import tempfile
from io import BytesIO

# Add src directory to Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.core.document_processor import DocumentProcessor
from src.utils.indian_language_detector import detect_indian_language

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_test_documents():
    """Create test documents in memory for testing"""
    
    # Create simple text files for testing
    test_docs = {}
    
    # Hindi text file
    hindi_content = """‡§Ø‡§π ‡§è‡§ï ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡§æ ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§π‡•à‡•§

‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∂‡•Ä‡§∞‡•ç‡§∑‡§ï
============

‡§Ø‡§π ‡§è‡§ï ‡§™‡•à‡§∞‡§æ‡§ó‡•ç‡§∞‡§æ‡§´ ‡§π‡•à ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§™‡§æ‡§† ‡§π‡•à‡•§ ‡§π‡§Æ‡•á‡§Ç ‡§á‡§∏‡•á ‡§∏‡§π‡•Ä ‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á ‡§™‡§π‡§ö‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§

‡§¶‡•Ç‡§∏‡§∞‡§æ ‡§∂‡•Ä‡§∞‡•ç‡§∑‡§ï
-----------

‡§Ø‡§π ‡§¶‡•Ç‡§∏‡§∞‡§æ ‡§™‡•à‡§∞‡§æ‡§ó‡•ç‡§∞‡§æ‡§´ ‡§π‡•à‡•§ ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§™‡§æ‡§† ‡§π‡•à‡•§

Mixed content: This paragraph has English text with ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∂‡§¨‡•ç‡§¶ mixed in.
"""
    
    # Kannada text file
    kannada_content = """‡≤á‡≤¶‡≥Å ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤¶‡≤æ‡≤ñ‡≤≤‡≥Ü‡≤Ø ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤â‡≤¶‡≤æ‡≤π‡≤∞‡≤£‡≥Ü‡≤Ø‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü‡•§

‡≤Æ‡≥Å‡≤ñ‡≥ç‡≤Ø ‡≤∂‡≥Ä‡≤∞‡≥ç‡≤∑‡≤ø‡≤ï‡≥Ü
===============

‡≤á‡≤¶‡≥Å ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤™‡≤†‡≥ç‡≤Ø‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤∞‡≥Å‡≤µ ‡≤™‡≥ç‡≤Ø‡≤æ‡≤∞‡≤æ‡≤ó‡≥ç‡≤∞‡≤æ‡≤´‡≥ç ‡≤Ü‡≤ó‡≤ø‡≤¶‡≥Ü‡•§ ‡≤®‡≤æ‡≤µ‡≥Å ‡≤á‡≤¶‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≤∞‡≤ø‡≤Ø‡≤æ‡≤ó‡≤ø ‡≤ó‡≥Å‡≤∞‡≥Å‡≤§‡≤ø‡≤∏‡≤¨‡≥á‡≤ï‡≥Å‡•§

‡≤é‡≤∞‡≤°‡≤®‡≥Ü‡≤Ø ‡≤∂‡≥Ä‡≤∞‡≥ç‡≤∑‡≤ø‡≤ï‡≥Ü
-----------------

‡≤á‡≤¶‡≥Å ‡≤é‡≤∞‡≤°‡≤®‡≥Ü‡≤Ø ‡≤™‡≥ç‡≤Ø‡≤æ‡≤∞‡≤æ‡≤ó‡≥ç‡≤∞‡≤æ‡≤´‡≥ç. ‡≤á‡≤¶‡≤∞‡≤≤‡≥ç‡≤≤‡≤ø ‡≤á‡≤®‡≥ç‡≤®‡≥Ç ‡≤ï‡≥Ü‡≤≤‡≤µ‡≥Å ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤™‡≤†‡≥ç‡≤Ø‡≤µ‡≤ø‡≤¶‡≥Ü‡•§

Mixed content: This paragraph has English text with ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤™‡≤¶‡≤ó‡≤≥‡≥Å mixed in.
"""

    # Create temporary files
    test_docs['hindi_text'] = create_temp_file(hindi_content, 'hindi_test.txt')
    test_docs['kannada_text'] = create_temp_file(kannada_content, 'kannada_test.txt')
    
    return test_docs

def create_temp_file(content, filename):
    """Create a temporary file with given content"""
    temp_dir = Path(tempfile.gettempdir()) / 'polydoc_test'
    temp_dir.mkdir(exist_ok=True)
    
    file_path = temp_dir / filename
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    return file_path

async def test_document_processing():
    """Test document processing with Hindi and Kannada files"""
    
    print("=" * 60)
    print("DOCUMENT PROCESSING TEST")
    print("=" * 60)
    
    try:
        # Initialize document processor
        processor = DocumentProcessor()
        print("‚úÖ DocumentProcessor initialized successfully")
        
        # Create test documents
        print("\nüìÑ Creating test documents...")
        test_docs = create_test_documents()
        
        for doc_type, file_path in test_docs.items():
            print(f"\nüîç Testing {doc_type.upper()} processing...")
            print(f"File: {file_path}")
            print("-" * 50)
            
            try:
                # Process document
                result = await processor.process_document(str(file_path))
                
                print(f"‚úÖ Processing successful!")
                print(f"   üìä Total elements: {len(result.elements)}")
                print(f"   üìÑ Total pages: {result.total_pages}")
                print(f"   üìÅ File type: {result.metadata.get('file_type', 'unknown')}")
                
                # Analyze language detection in elements
                languages = {}
                for element in result.elements:
                    if element.language:
                        languages[element.language] = languages.get(element.language, 0) + 1
                
                print(f"   üåê Languages detected: {languages}")
                
                # Show first few elements
                print("   üìù First few elements:")
                for i, element in enumerate(result.elements[:3]):
                    print(f"      {i+1}. [{element.element_type}] {element.text[:80]}...")
                    print(f"         Language: {element.language}, Confidence: {element.confidence:.2f}")
                
                # Test individual language detection on elements
                print("   üîç Individual language detection test:")
                for i, element in enumerate(result.elements[:2]):  # Test first 2 elements
                    detected = detect_indian_language(element.text)
                    print(f"      Element {i+1}: '{element.text[:50]}...'")
                    print(f"      ‚Üí Detected: {detected.language_name} ({detected.language_code}) - {detected.confidence:.2f}")
                
            except Exception as e:
                print(f"‚ùå Processing failed: {e}")
                import traceback
                traceback.print_exc()
            
            print()
    
    except Exception as e:
        print(f"‚ùå Document processor initialization failed: {e}")
        import traceback
        traceback.print_exc()

def test_mixed_language_detection():
    """Test mixed language detection improvements"""
    
    print("=" * 60)
    print("MIXED LANGUAGE DETECTION TEST")
    print("=" * 60)
    
    mixed_texts = [
        "This document contains ‡§π‡§ø‡§Ç‡§¶‡•Ä text in the middle.",
        "Here we have ‡≤ï‡≤®‡≥ç‡≤®‡≤° script mixed with English.",
        "‡§Ø‡§π mostly Hindi ‡§π‡•à with some English words.",
        "‡≤á‡≤¶‡≥Å mostly Kannada with some English words.",
        "Complete English text without any Indian languages.",
        "‡§™‡•Ç‡§∞‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§™‡§æ‡§† ‡§¨‡§ø‡§®‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§ï‡•á‡•§",
        "‡≤∏‡≤Ç‡≤™‡≥Ç‡≤∞‡≥ç‡≤£‡≤µ‡≤æ‡≤ó‡≤ø ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤™‡≤†‡≥ç‡≤Ø ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤á‡≤Ç‡≤ó‡≥ç‡≤≤‡≥Ä‡≤∑‡≥ç ‡≤á‡≤≤‡≥ç‡≤≤‡≤¶‡≥Ü‡•§",
    ]
    
    for i, text in enumerate(mixed_texts, 1):
        print(f"\nüîç Test {i}: {text}")
        print("-" * 50)
        
        try:
            detection = detect_indian_language(text)
            print(f"‚úÖ Result: {detection.language_name} ({detection.language_code})")
            print(f"   Script: {detection.script}")
            print(f"   Confidence: {detection.confidence:.2f}")
        except Exception as e:
            print(f"‚ùå Error: {e}")

def cleanup_test_files(test_docs):
    """Clean up temporary test files"""
    for doc_type, file_path in test_docs.items():
        try:
            if file_path.exists():
                file_path.unlink()
                print(f"üóëÔ∏è  Cleaned up {file_path.name}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not clean up {file_path.name}: {e}")

async def main():
    """Main test function"""
    print("üß™ POLYDOC COMPREHENSIVE HINDI & KANNADA TEST")
    print("Testing document processing and language detection")
    
    test_docs = {}
    try:
        # Test mixed language detection first
        test_mixed_language_detection()
        
        # Then test document processing
        await test_document_processing()
        
        print("\n" + "=" * 60)
        print("‚úÖ COMPREHENSIVE TEST COMPLETED")
        print("=" * 60)
        
    except Exception as e:
        print(f"\n‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Clean up test files if any were created
        if test_docs:
            cleanup_test_files(test_docs)

if __name__ == "__main__":
    asyncio.run(main())
